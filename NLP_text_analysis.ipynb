{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8020ba99",
   "metadata": {},
   "source": [
    "# Topic Modeling Exercise\n",
    "Presented by Brandi Smith  \n",
    "Predictive Analytics Seminar  \n",
    "10/24/2022\n",
    "### About Dataset\n",
    "r/VaccineMyths in Reddit: https://www.kaggle.com/datasets/gpreda/reddit-vaccine-myths?resource=download\n",
    "### Import Data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceb5d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reddit=pd.read_csv(\"reddit_vm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f825298",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39cf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31750349",
   "metadata": {},
   "source": [
    "### Clean data\n",
    "1. Create a new column where if `title != Comment`, return the title and if ` title == Comment` return the body\n",
    "2. Lower case the text in the new column\n",
    "3. remove stop words - small dataset\n",
    "4. Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NEW COLUMN \n",
    "def new_column(col):   \n",
    "    if col.title != \"Comment\":\n",
    "        return col.title\n",
    "    else:\n",
    "        return col.body\n",
    "\n",
    "reddit[\"text\"] = reddit.apply(new_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6a275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lower case text\n",
    "reddit[\"text\"] = reddit[\"text\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823aab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "reddit['text_without_stopwords'] = reddit['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729f873f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that stop words are removed\n",
    "reddit['text']=reddit['text_without_stopwords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34809eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468d569",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#remove punctuation\n",
    "reddit[\"text\"] = reddit[\"text\"].str.replace(r'[^\\w\\s]+', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816be31e",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967ee909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of posts by year\n",
    "reddit['n_posts']=1\n",
    "reddit['timestamp']= pd.to_datetime(reddit['timestamp'])\n",
    "reddit['year'] = reddit['timestamp'].dt.strftime('%Y')\n",
    "#reddit['month_year'] = reddit['timestamp'].dt.strftime('%B-%Y')\n",
    "\n",
    "year_val= reddit[[\"year\", \"n_posts\"]]\n",
    "plot_dat=year_val.groupby('year').sum()\n",
    "plot_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768915b4",
   "metadata": {},
   "source": [
    "#### Implications in peak number of posts\n",
    "**2014 : Ebola virus enters U.S.: https://en.wikipedia.org/wiki/Ebola_virus_cases_in_the_United_States**  \n",
    "**2019 : Onset of COVID-19 Pandemic** \n",
    "\n",
    "#### Follow-up questions? \n",
    "1. What topics were people talking about around vaccine myths during either ebola endemic or Covid-19 pandemic?  \n",
    "2. Do the topics differ in 2014 versus 2019 and 2020? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff576d55",
   "metadata": {},
   "source": [
    "### BERTopic Implementation\n",
    "Determine topics for 2014 (Ebola) and 2019-2020 (Covid)  \n",
    "\n",
    "*Note: Install HBDSCAN before BERTopic  \n",
    "`conda install -c conda-forge hdbscan` then  \n",
    "`pip install BERTopic`*\n",
    "\n",
    "#### Ebola topic modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720b4514",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "ebola= reddit[(reddit['year'].str.contains(\"2014\"))]\n",
    "ebola_list=ebola.text.to_list()\n",
    "#ebola_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aaa4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimension reduction method\n",
    "from umap import UMAP\n",
    "umap_model = UMAP(random_state=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use HBDScan as clustering method\n",
    "from hdbscan import HDBSCAN\n",
    "cluster_method=HDBSCAN(min_cluster_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37442823",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model = BERTopic(hdbscan_model=cluster_method, umap_model=umap_model)\n",
    "topics, probs = topic_model.fit_transform(ebola_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f0aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9fa0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3285a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#observe which posts topics were derived from\n",
    "topic_model.get_representative_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8c9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the topics\n",
    "topic_model.visualize_hierarchy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4978da28",
   "metadata": {},
   "source": [
    "#### Covid 19 topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a45b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "covid= reddit[(reddit['year'].str.contains(\"2019\")) | (reddit['year'].str.contains(\"2020\"))]\n",
    "covid=covid.text.to_list()\n",
    "#covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4359541c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimension reduction method\n",
    "from umap import UMAP\n",
    "umap_model = UMAP(random_state=81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199dbfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "cluster_method=HDBSCAN(min_cluster_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7af8bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model2 = BERTopic(hdbscan_model=cluster_method)\n",
    "topics2, probs2 = topic_model2.fit_transform(covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6b8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model2.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876123f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model2.get_topic(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636dbf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model2.get_topic(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e1b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#observe which posts topics were derived from\n",
    "topic_model2.get_representative_docs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model2.visualize_hierarchy()\n",
    "#illustrates how topics were clustered from agglomerate clusteing approach (bottom-up)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88164ba0",
   "metadata": {},
   "source": [
    "### Follow-up question?\n",
    "\n",
    "Does the word vaccine (or the like) correlate with uptick posts around each corresponding event (ebola vs. covid19)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60275999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the frequency of antivax in our dataframe\n",
    "reddit['vax']=reddit.text.str.contains('vax|vaccination|vaccines|vaccine', na=False, regex=True)#where na's present bool value=False\n",
    "\n",
    "def mentions(col):   \n",
    "    if col.vax == True:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "reddit[\"vax_mention\"] = reddit.apply(mentions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0c7bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change timestamp Object to datetime64\n",
    "reddit[\"year\"] = reddit[\"year\"].astype(\"datetime64\")\n",
    " \n",
    "# Setting the Date as index\n",
    "reddit = reddit.set_index(\"year\")\n",
    "reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.groupby('year').sum('vax_mention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7060fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vax_mention=reddit.groupby('year').sum('vax_mention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc03cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the raw number of mentions over time\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Using a inbuilt style to change\n",
    "# the look and feel of the plot\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    " \n",
    "# setting figure size to 12, 10\n",
    "plt.figure(figsize=(12, 10))\n",
    " \n",
    "# Labelling the axes and setting\n",
    "# a title\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Mentions of Vaccine\")\n",
    "plt.title(\"# of mentions over time\")\n",
    " \n",
    "# plotting the \"A\" column alone\n",
    "plt.plot(vax_mention[\"vax_mention\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2dc387",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "1. Data cleaning can increase the coherence of resulting topics in models\n",
    "2. Illustrating trends in social media data allow us to correlate text data to events in time and further increase our understanding of resulting topics\n",
    "3. including clustering methods such as HDBScan can improve the reproducib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3ebf1",
   "metadata": {},
   "source": [
    "## Sources\n",
    "1. Pandas documentation: https://pandas.pydata.org/ (popular python data analysis tool)\n",
    "2. Sentiment analysis of vaccine myths data : https://www.kaggle.com/code/khsamaha/reddit-vaccine-myths-eda-and-text-analysis\n",
    "3. BERTopic tutorial: https://maartengr.github.io/BERTopic/index.html\n",
    "4. Plotting time series: https://www.geeksforgeeks.org/how-to-plot-timeseries-based-charts-using-pandas/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
